{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Big O Notation\n",
    "First introduced by Bachmann in 1894 in a research paper to approximate an algorithm's growth. He wrote:\n",
    "\"... with the symbol *O(n)* we express a magnitude whose order in respect to `n` does not exceed the order of `n`\" (Bachmann 1894, p. 401)\n",
    "\n",
    "Big-O notation provides a way to describe the long-term growth rate of an algorithm's performance. As the input size grows, the runtime of the algorithm also increases.\n",
    "\n",
    "## Rules\n",
    "1. When an algorithm operates with a sequential structure, executing one function `f(n)` followed by another function `g(n)`, the overall complexity of the tasks becomes a sum of the two. Therefore, it's represented as `O(f(n)+g(n))`\n",
    "2. For algorithms that have a divided structure (where one task splits into multiple sub-tasks), if each sub-task has a complexity of `f(n)`, the algorithm's overall complexity remains `O(f(n))` (assuming the sub-tasks are processed simultaneously or don't depend on each other).\n",
    "3. With recursive algorithms, if an algorithm calls itself with a fraction of the input size (`f(n/2)` or `f(n/3)`) and performs other operations taking `g(n)` steps. The combined complexity can be denoted as `O(f(n/2)+g(n))` or `O(f(n/3)+g(n))`, depending on the fraction.\n",
    "4. For nested recursive structures, if an algorithm divides its input into smaller chunks and processes each recursively, and each chunk is further divided and processed similarly, the overall complexity would be a cumulative representation of these nested operations. For instance, if a problem of size 'n' divides into sub-problems of size n/2, and these sub-problems are similarly processed, the complexity might be expressed as `O(f(n)*g(n/2))`.\n",
    "5. When calculating the complexity of an algorithm, ignore constant multiples. if `k` is a constant, `O(kf(n))` is the same as `O(f(n))`. Also, `O(f(k * n))` is the same as `O(f(n))`, thus `O(5n^2) = O(n^2)` and `O((3n^2)) = O(n^2)`.\n",
    "\n",
    "> ### Note\n",
    "> * The complexity quantified by Big O notation is only an estimate.\n",
    "> * For smaller datasets, the time complexity might not be a significant concern.\n",
    "> * `T(n)` time complexity is more than the original function. A good choice of `T(n)` will try to create a tight upper bound for `F(n)`\n",
    "\n",
    "## Big O notation types\n",
    "| Complexity Class | Name        | Example Operations                    |\n",
    "|------------------|-------------|---------------------------------------|\n",
    "| `O(1)`           | Constant    | Append, get item, set item.           |\n",
    "| `O(logn)`        | Logarithmic | Finding an element in a sorted array. |\n",
    "| `O(n)`           | Linear      | Copy, insert, delete, iteration       |\n",
    "| `O(n^2)`         | Quadratic   | Nested loops                          |\n"
   ],
   "id": "71887dd8d1046959"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

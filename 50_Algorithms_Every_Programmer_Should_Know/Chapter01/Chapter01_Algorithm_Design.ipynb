{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# The Phases of an Algorithm\n",
    "\n",
    "The process starts with understanding the requirements from the problem statement that details what needs to be done.\n",
    "Once the problem is clearly stated, it leads us to the development (coding) phase.\n",
    "\n",
    "### 1. The Design Phase\n",
    "This is where we evision and document the architecture, logic, and implementation details of the algorithm. It's important to keep accuracy and performance in mind when choosing between candidate algorithms. Some algorithms may be very accurate but may take considerable time to run, while some algorithms may be more efficient. The tradeoffs between algorithms should be studied (satisfactory performance & reasonable accuracy).\n",
    "\n",
    "### 2. The Coding Phase\n",
    "Then, we begin converting the designed algorithm into a computer program.\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm Design Techniques\n",
    "An algorithm is a mathematical solution to a real-world problem. \n",
    "Understanding the complexity of a problem helps us design an appropriate solution if we characterize the problem in terms of its needs and complexity.\n",
    "\n",
    "1. Is this algorithm producing the result we expected?\n",
    "2. Is this the most optimal way to get these results?\n",
    "3. How is the algorithm going to perform on larger datasets?\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm Types\n",
    "### Data-Intensive Algorithms\n",
    "These are designed to deal with a large amount of data. Expected to have relatively simplistic processing requirements. The size of the data is expeted to be much larger than the memory of the processing engine, an iterative processing design may need to be developed to efficiently process the data according to the requirements.\n",
    "\n",
    "### Compute-Intensive Algorithms\n",
    "These have considerable processing requirements but do not involve large amounts of data. Finding a strategy to divide the algorithm into different phases so that at least some of the phases are parallelized is key to maximizing the performance of the algorithm.\n",
    "\n",
    "### Both Data and Compute-Intensive Algorithms\n",
    " Some algorithms deal with a large amount of data and also have considerable computing requirements. These are the most resource-intensive algorithms and require careful design of the algorithm and intelligent allocation of available resources.\n",
    " \n",
    "---\n",
    "\n",
    "## The Data Dimension\n",
    "To categorize the data dimension of the problem, we look at its volume, velocity, and variety (the **3Vs**)\n",
    "1. The **volume** is the expected size of the data that the algorithm will process.\n",
    "2. The **velocity** is the expected rate of new data generation when the algorithm is used. It can be zero.\n",
    "3. The **variety** quantifies how many different types of data the designed algorithm is expected to deal with.\n",
    "\n",
    "---\n",
    "\n",
    "## Space Complexity Analysis\n",
    "Space complexity analysis estimates the amount of memory required by the algorithm to process input data. These tend to be iterative, and so, it is important to first classify the type of iterative algorith we plan to use. An iterative algorithm can use one of the following three types of iterations:\n",
    "* **Converging Iterations**: The amount of data is sequentially decreased after each iteration. The main challenge is to tackle the space complexity of the initial iterations.\n",
    "* **Diverging Iterations**: The amount of data is sequentially increased after each iteration. Constraints can be be set to limit the number of iterations and/or by setting a limit on the size of initial data.\n",
    "* **Flat Iterations**: The amount of data remains constant after each iteration.\n",
    "\n",
    "The following are guidelines to minimize the space complexity:\n",
    "* Whenever possible, try to design an algorithm as iterative\n",
    "* While designing an iterative algorithm, whenever there is a choice, prefer a larger number of iterations over a smaller number of iterations. A find-grained larger number of iterations is expected to have less space complexity.\n",
    "* Algorithms should bring only the information needed for current processing into memory. Whatever is not needed should be flushed out from the memory.\n",
    "\n",
    "## Time Complexity Analysis\n",
    "Time complexity analysis estimates how long it will take for an algorithm to complete its assigned job based on its structure.\n",
    "The overall goal is to try and answer these important two questions:\n",
    "1. Will this algorithm scale?\n",
    "2. How well will this algorithm handle larger datasets?\n",
    "\n",
    "Two basic approaches to calculating the time complexity of an algorithm:\n",
    "1. **Post-implementation profiling approach**: Different candidate algorithms are implemented, and their performance is compared.\n",
    "2. **Pre-implementation theoretical approach**: The performance of each algorithm is approximated mathematically before running an algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "## Validating an Algorithm\n",
    "Algorithms can be divided further into the following two types based on assumptions or approximation used to simplify the logic to make them run faster:\n",
    "* **An exact algorithm**: Exact algorithms are expected to produce a precise solution without introducing any assumptions or approximations.\n",
    "* **An approximate algorithm**: When the problem complexity is too much to handle for the given resources, we simplify our problem by making some assumptions. The algorithms based on these simplifications or assumptions are called approximate algorithms, which don't quite give us the precise solution.\n",
    "\n",
    "---\n",
    "\n",
    "# Big O Notation\n",
    "First introduced by Bachmann in 1894 in a research paper to approximate an algorithm's growth. He wrote:\n",
    "\"... with the symbol *O(n)* we express a magnitude whose order in respect to `n` does not exceed the order of `n`\" (Bachmann 1894, p. 401)\n",
    "\n",
    "Big-O notation provides a way to describe the long-term growth rate of an algorithm's performance. As the input size grows, the runtime of the algorithm also increases.\n",
    "\n",
    "## Rules\n",
    "1. When an algorithm operates with a sequential structure, executing one function `f(n)` followed by another function `g(n)`, the overall complexity of the tasks becomes a sum of the two. Therefore, it's represented as `O(f(n)+g(n))`\n",
    "2. For algorithms that have a divided structure (where one task splits into multiple sub-tasks), if each sub-task has a complexity of `f(n)`, the algorithm's overall complexity remains `O(f(n))` (assuming the sub-tasks are processed simultaneously or don't depend on each other).\n",
    "3. With recursive algorithms, if an algorithm calls itself with a fraction of the input size (`f(n/2)` or `f(n/3)`) and performs other operations taking `g(n)` steps. The combined complexity can be denoted as `O(f(n/2)+g(n))` or `O(f(n/3)+g(n))`, depending on the fraction.\n",
    "4. For nested recursive structures, if an algorithm divides its input into smaller chunks and processes each recursively, and each chunk is further divided and processed similarly, the overall complexity would be a cumulative representation of these nested operations. For instance, if a problem of size 'n' divides into sub-problems of size n/2, and these sub-problems are similarly processed, the complexity might be expressed as `O(f(n)*g(n/2))`.\n",
    "5. When calculating the complexity of an algorithm, ignore constant multiples. if `k` is a constant, `O(kf(n))` is the same as `O(f(n))`. Also, `O(f(k * n))` is the same as `O(f(n))`, thus `O(5n^2) = O(n^2)` and `O((3n^2)) = O(n^2)`.\n",
    "\n",
    "> ### Note\n",
    "> * The complexity quantified by Big O notation is only an estimate.\n",
    "> * For smaller datasets, the time complexity might not be a significant concern.\n",
    "> * `T(n)` time complexity is more than the original function. A good choice of `T(n)` will try to create a tight upper bound for `F(n)`\n",
    "\n",
    "## Big O notation types\n",
    "| Complexity Class | Name        | Example Operations                    |\n",
    "|------------------|-------------|---------------------------------------|\n",
    "| `O(1)`           | Constant    | Append, get item, set item.           |\n",
    "| `O(logn)`        | Logarithmic | Finding an element in a sorted array. |\n",
    "| `O(n)`           | Linear      | Copy, insert, delete, iteration       |\n",
    "| `O(n^2)`         | Quadratic   | Nested loops                          |\n",
    "\n"
   ],
   "id": "774c121b7ff74df5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
